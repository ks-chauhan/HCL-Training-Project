{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBRl5eOK2Nn5JsYjqZa9mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ks-chauhan/HCL-Training-Project/blob/main/Notebooks/Training_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbb97P1hBJFX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import transformers\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "JWWqk7OJBUWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/HCL Training Project/guardian_headlines.csv\")"
      ],
      "metadata": {
        "id": "6DDzQRzjBU_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"tag\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "pJg2FfLCBa5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "9lmtyCXQBcTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['Topic'])\n",
        "\n",
        "num_labels = len(le.classes_)\n",
        "print(\"Number of unique labels:\", num_labels)"
      ],
      "metadata": {
        "id": "eTv-xEYvBdoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=18, stratify=df['label'])"
      ],
      "metadata": {
        "id": "DOXuFYD4BfVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting to Hugging Face Datasets\n",
        "from datasets import Dataset\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df[['headline', 'label']])\n",
        "test_dataset = Dataset.from_pandas(test_df[['headline', 'label']])"
      ],
      "metadata": {
        "id": "zC1QpZpxBhAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the pre-trained model and tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)"
      ],
      "metadata": {
        "id": "K8ERHpoyBioL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "    return tokenizer(\n",
        "        x[\"headline\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=64\n",
        "    )\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.remove_columns(['headline'])\n",
        "test_dataset = test_dataset.remove_columns(['headline'])\n",
        "train_dataset.set_format('torch')\n",
        "test_dataset.set_format('torch')"
      ],
      "metadata": {
        "id": "IdgMhGTIBkE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up training arguments\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=50\n",
        ")"
      ],
      "metadata": {
        "id": "TuEeD0dBBl2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the compute_metrics function\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        \"f1\": f1,\n",
        "        \"accuracy\": acc\n",
        "    }"
      ],
      "metadata": {
        "id": "xLtsxqMpBnnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the Trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "d2bk14SrBpL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "UQatMmcjBrDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "apPca1ypBsnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Confusion Matrix\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "\n",
        "y_true = predictions.label_ids\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "\n",
        "print(\"\\nLabel ID â†’ Class Name Mapping:\")\n",
        "for idx, class_name in enumerate(le.classes_):\n",
        "    print(f\"{idx} : {class_name}\")"
      ],
      "metadata": {
        "id": "c2sL1I4tBua-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and tokenizer\n",
        "\n",
        "trainer.save_model(\"/content/drive/MyDrive/HCL Training Project/final_model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/HCL Training Project/final_model\")"
      ],
      "metadata": {
        "id": "_7fK66JTBwop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}